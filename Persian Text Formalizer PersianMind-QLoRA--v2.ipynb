{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-17T14:19:51.262538Z",
     "iopub.status.busy": "2025-08-17T14:19:51.262299Z",
     "iopub.status.idle": "2025-08-17T14:19:51.906201Z",
     "shell.execute_reply": "2025-08-17T14:19:51.905404Z",
     "shell.execute_reply.started": "2025-08-17T14:19:51.262512Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ParsMap.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:32:43.941409Z",
     "iopub.status.busy": "2025-08-17T14:32:43.940883Z",
     "iopub.status.idle": "2025-08-17T14:32:44.292022Z",
     "shell.execute_reply": "2025-08-17T14:32:44.291253Z",
     "shell.execute_reply.started": "2025-08-17T14:32:43.941384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!touch ~/.kaggle/kaggle.json\n",
    "\n",
    "api_token = {\"username\":\"\",\"key\":\"\"}\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:33:15.066197Z",
     "iopub.status.busy": "2025-08-17T14:33:15.065551Z",
     "iopub.status.idle": "2025-08-17T14:34:47.915255Z",
     "shell.execute_reply": "2025-08-17T14:34:47.914555Z",
     "shell.execute_reply.started": "2025-08-17T14:33:15.066165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file downloaded to /kaggle/working/PersianMind-V1.0-formalizer-lora/README.md\n",
      "Output file downloaded to /kaggle/working/PersianMind-V1.0-formalizer-lora/adapter_config.json\n",
      "Output file downloaded to /kaggle/working/PersianMind-V1.0-formalizer-lora/adapter_model.safetensors\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/README.md\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/adapter_config.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/adapter_model.safetensors\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/added_tokens.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/optimizer.pt\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/rng_state.pth\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/scaler.pt\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/scheduler.pt\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/special_tokens_map.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/tokenizer.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/tokenizer.model\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/tokenizer_config.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/trainer_state.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2500/training_args.bin\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/README.md\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/adapter_config.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/adapter_model.safetensors\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/added_tokens.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/optimizer.pt\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/rng_state.pth\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/scaler.pt\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/scheduler.pt\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/special_tokens_map.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/tokenizer.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/tokenizer.model\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/tokenizer_config.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/trainer_state.json\n",
      "Output file downloaded to /kaggle/working/persianmind-formalizer-lora/checkpoint-2814/training_args.bin\n",
      "Output file downloaded to /kaggle/working/wandb/settings\n",
      "Kernel log downloaded to /kaggle/working/persianmind-v333.log \n"
     ]
    }
   ],
   "source": [
    "!kaggle kernels output aylinnaebzadeh/persianmind-v333 -p /kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "- https://tuanatran.medium.com/fine-tuning-large-language-model-with-hugging-face-pytorch-adce80dce2ad\n",
    "- https://www.kaggle.com/code/shayanbemanian/persian-informal-to-formal-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W&B first of all:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:44:54.629852Z",
     "iopub.status.busy": "2025-08-17T14:44:54.629564Z",
     "iopub.status.idle": "2025-08-17T14:45:15.568315Z",
     "shell.execute_reply": "2025-08-17T14:45:15.567453Z",
     "shell.execute_reply.started": "2025-08-17T14:44:54.629826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hW&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.\n",
      "W&B disabled.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "# ------------------------\n",
    "!pip uninstall -y --quiet wandb\n",
    "!pip install --quiet wandb==0.17.5 \n",
    "# ------------------------\n",
    "import wandb\n",
    "!wandb offline\n",
    "!wandb disabled\n",
    "# ------------------------\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:45:15.570478Z",
     "iopub.status.busy": "2025-08-17T14:45:15.570162Z",
     "iopub.status.idle": "2025-08-17T14:46:58.486148Z",
     "shell.execute_reply": "2025-08-17T14:46:58.485396Z",
     "shell.execute_reply.started": "2025-08-17T14:45:15.570441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.0/894.0 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.1 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.1 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade datasets transformers evaluate sentencepiece accelerate \n",
    "!pip install --quiet dadmatools[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:46:58.487356Z",
     "iopub.status.busy": "2025-08-17T14:46:58.487105Z",
     "iopub.status.idle": "2025-08-17T14:47:08.521185Z",
     "shell.execute_reply": "2025-08-17T14:47:08.520382Z",
     "shell.execute_reply.started": "2025-08-17T14:46:58.487332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.9/503.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U --quiet peft accelerate\n",
    "!pip install -U --quiet bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:08.523338Z",
     "iopub.status.busy": "2025-08-17T14:47:08.523064Z",
     "iopub.status.idle": "2025-08-17T14:47:13.560754Z",
     "shell.execute_reply": "2025-08-17T14:47:13.560021Z",
     "shell.execute_reply.started": "2025-08-17T14:47:08.523315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --quiet rouge-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:13.562219Z",
     "iopub.status.busy": "2025-08-17T14:47:13.561932Z",
     "iopub.status.idle": "2025-08-17T14:47:36.529255Z",
     "shell.execute_reply": "2025-08-17T14:47:36.528672Z",
     "shell.execute_reply.started": "2025-08-17T14:47:13.562186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-17 14:47:23.073298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755442043.239053      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755442043.285453      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dadmatools.normalizer import Normalizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, get_linear_schedule_with_warmup\n",
    "from transformers import  BitsAndBytesConfig, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:36.530608Z",
     "iopub.status.busy": "2025-08-17T14:47:36.530066Z",
     "iopub.status.idle": "2025-08-17T14:47:36.535513Z",
     "shell.execute_reply": "2025-08-17T14:47:36.534733Z",
     "shell.execute_reply.started": "2025-08-17T14:47:36.530583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:36.536654Z",
     "iopub.status.busy": "2025-08-17T14:47:36.536381Z",
     "iopub.status.idle": "2025-08-17T14:47:42.836092Z",
     "shell.execute_reply": "2025-08-17T14:47:42.835349Z",
     "shell.execute_reply.started": "2025-08-17T14:47:36.536631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inFormalForm</th>\n",
       "      <th>formalForm</th>\n",
       "      <th>formalWords</th>\n",
       "      <th>inFormalWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>من دوس دارم برم خونه درس بخونم.</td>\n",
       "      <td>من دوست دارم که به خانه بروم تا درس بخوانم.</td>\n",
       "      <td>من/دوست/دارم/بروم/خانه/درس/بخوانم</td>\n",
       "      <td>من/دوس/دارم/برم/خونه/درس/بخونم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>میتونی منو ببری خونمون یکم نون وردارم؟</td>\n",
       "      <td>می‌توانی من را به خانه‌مان ببری تا کمی نان برد...</td>\n",
       "      <td>می‌توانی/من را/ببری/خانه‌مان/کمی/نان/بردارم</td>\n",
       "      <td>میتونی/منو/ببری/خونمون/یکم/نون/وردارم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>رفتم درمونگاه واسه بچم دوا بگیرم، یهو بارون گرفت</td>\n",
       "      <td>به درمانگاه رفتم تا برای بچه‌ام دوا بگیرم که ی...</td>\n",
       "      <td>رفتم/درمانگاه/برای/بچه‌ام/دوا/بگیرم/یکهو/باران...</td>\n",
       "      <td>رفتم/درمونگاه/واسه/بچم/دوا/بگیرم/یهو/بارون/گرفت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اون که خدا شاهده مث دیوونه هاس</td>\n",
       "      <td>خدا شاهد است که او مثل دیوانه‌ها است.</td>\n",
       "      <td>شاهد است/او/که/خدا/مثل/دیوانه‌ها است</td>\n",
       "      <td>شاهده/اون/که/خدا/مث/دیوونه هاس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>یه سری آدما هستن که هر قدر خوبی کنی اصلن انگار...</td>\n",
       "      <td>یک سری آدم‌ها هستند که هر قدر هم خوبی کنی، اصل...</td>\n",
       "      <td>یک/سری/آدم‌ها/هستند/که/هر/قدر/خوبی/کنی/اصلاً/ا...</td>\n",
       "      <td>یه/سری/آدما/هستن/که/هر/قدر/خوبی/کنی/اصلن/انگار...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        inFormalForm  \\\n",
       "0                    من دوس دارم برم خونه درس بخونم.   \n",
       "1             میتونی منو ببری خونمون یکم نون وردارم؟   \n",
       "2   رفتم درمونگاه واسه بچم دوا بگیرم، یهو بارون گرفت   \n",
       "3                     اون که خدا شاهده مث دیوونه هاس   \n",
       "4  یه سری آدما هستن که هر قدر خوبی کنی اصلن انگار...   \n",
       "\n",
       "                                          formalForm  \\\n",
       "0        من دوست دارم که به خانه بروم تا درس بخوانم.   \n",
       "1  می‌توانی من را به خانه‌مان ببری تا کمی نان برد...   \n",
       "2  به درمانگاه رفتم تا برای بچه‌ام دوا بگیرم که ی...   \n",
       "3              خدا شاهد است که او مثل دیوانه‌ها است.   \n",
       "4  یک سری آدم‌ها هستند که هر قدر هم خوبی کنی، اصل...   \n",
       "\n",
       "                                         formalWords  \\\n",
       "0                  من/دوست/دارم/بروم/خانه/درس/بخوانم   \n",
       "1        می‌توانی/من را/ببری/خانه‌مان/کمی/نان/بردارم   \n",
       "2  رفتم/درمانگاه/برای/بچه‌ام/دوا/بگیرم/یکهو/باران...   \n",
       "3               شاهد است/او/که/خدا/مثل/دیوانه‌ها است   \n",
       "4  یک/سری/آدم‌ها/هستند/که/هر/قدر/خوبی/کنی/اصلاً/ا...   \n",
       "\n",
       "                                       inFormalWords  \n",
       "0                     من/دوس/دارم/برم/خونه/درس/بخونم  \n",
       "1              میتونی/منو/ببری/خونمون/یکم/نون/وردارم  \n",
       "2    رفتم/درمونگاه/واسه/بچم/دوا/بگیرم/یهو/بارون/گرفت  \n",
       "3                     شاهده/اون/که/خدا/مث/دیوونه هاس  \n",
       "4  یه/سری/آدما/هستن/که/هر/قدر/خوبی/کنی/اصلن/انگار...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parsmap = pd.read_excel(\"/kaggle/input/ParsMap.xlsx\")\n",
    "df_parsmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:42.837450Z",
     "iopub.status.busy": "2025-08-17T14:47:42.836851Z",
     "iopub.status.idle": "2025-08-17T14:47:42.851093Z",
     "shell.execute_reply": "2025-08-17T14:47:42.850314Z",
     "shell.execute_reply.started": "2025-08-17T14:47:42.837429Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "من دوس دارم برم خونه درس بخونم.\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(\n",
    "    full_cleaning=False,\n",
    "    unify_chars=True,\n",
    "    refine_punc_spacing=True,\n",
    "    remove_extra_space=True,\n",
    "    remove_puncs=False,\n",
    "    remove_html=True,\n",
    "    remove_stop_word=False,\n",
    "    replace_email_with=\"<EMAIL>\",\n",
    "    replace_number_with=None,\n",
    "    replace_url_with=\"\",\n",
    "    replace_mobile_number_with=None,\n",
    "    replace_emoji_with=None,\n",
    "    replace_home_number_with=None\n",
    ")\n",
    "\n",
    "text = 'من دوس دارم برم خونه درس بخونم    .'\n",
    "print(normalizer.normalize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:42.852241Z",
     "iopub.status.busy": "2025-08-17T14:47:42.851924Z",
     "iopub.status.idle": "2025-08-17T14:47:42.862150Z",
     "shell.execute_reply": "2025-08-17T14:47:42.861378Z",
     "shell.execute_reply.started": "2025-08-17T14:47:42.852221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return normalizer.normalize(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:42.864451Z",
     "iopub.status.busy": "2025-08-17T14:47:42.864246Z",
     "iopub.status.idle": "2025-08-17T14:47:56.495620Z",
     "shell.execute_reply": "2025-08-17T14:47:56.494997Z",
     "shell.execute_reply.started": "2025-08-17T14:47:42.864430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50014/50014 [00:07<00:00, 7022.35it/s]\n",
      "100%|██████████| 50014/50014 [00:06<00:00, 7714.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inFormalForm</th>\n",
       "      <th>formalForm</th>\n",
       "      <th>formalWords</th>\n",
       "      <th>inFormalWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>من دوس دارم برم خونه درس بخونم.</td>\n",
       "      <td>من دوست دارم که به خانه بروم تا درس بخوانم.</td>\n",
       "      <td>من/دوست/دارم/بروم/خانه/درس/بخوانم</td>\n",
       "      <td>من/دوس/دارم/برم/خونه/درس/بخونم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>میتونی منو ببری خونمون یکم نون وردارم؟</td>\n",
       "      <td>می‌توانی من را به خانه‌مان ببری تا کمی نان برد...</td>\n",
       "      <td>می‌توانی/من را/ببری/خانه‌مان/کمی/نان/بردارم</td>\n",
       "      <td>میتونی/منو/ببری/خونمون/یکم/نون/وردارم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>رفتم درمونگاه واسه بچم دوا بگیرم، یهو بارون گرفت</td>\n",
       "      <td>به درمانگاه رفتم تا برای بچه‌ام دوا بگیرم که ی...</td>\n",
       "      <td>رفتم/درمانگاه/برای/بچه‌ام/دوا/بگیرم/یکهو/باران...</td>\n",
       "      <td>رفتم/درمونگاه/واسه/بچم/دوا/بگیرم/یهو/بارون/گرفت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اون که خدا شاهده مث دیوونه هاس</td>\n",
       "      <td>خدا شاهد است که او مثل دیوانه‌ها است.</td>\n",
       "      <td>شاهد است/او/که/خدا/مثل/دیوانه‌ها است</td>\n",
       "      <td>شاهده/اون/که/خدا/مث/دیوونه هاس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>یه سری آدما هستن که هر قدر خوبی کنی اصلن انگار...</td>\n",
       "      <td>یک سری آدم‌ها هستند که هر قدر هم خوبی کنی، اصل...</td>\n",
       "      <td>یک/سری/آدم‌ها/هستند/که/هر/قدر/خوبی/کنی/اصلاً/ا...</td>\n",
       "      <td>یه/سری/آدما/هستن/که/هر/قدر/خوبی/کنی/اصلن/انگار...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        inFormalForm  \\\n",
       "0                    من دوس دارم برم خونه درس بخونم.   \n",
       "1             میتونی منو ببری خونمون یکم نون وردارم؟   \n",
       "2   رفتم درمونگاه واسه بچم دوا بگیرم، یهو بارون گرفت   \n",
       "3                     اون که خدا شاهده مث دیوونه هاس   \n",
       "4  یه سری آدما هستن که هر قدر خوبی کنی اصلن انگار...   \n",
       "\n",
       "                                          formalForm  \\\n",
       "0        من دوست دارم که به خانه بروم تا درس بخوانم.   \n",
       "1  می‌توانی من را به خانه‌مان ببری تا کمی نان برد...   \n",
       "2  به درمانگاه رفتم تا برای بچه‌ام دوا بگیرم که ی...   \n",
       "3              خدا شاهد است که او مثل دیوانه‌ها است.   \n",
       "4  یک سری آدم‌ها هستند که هر قدر هم خوبی کنی، اصل...   \n",
       "\n",
       "                                         formalWords  \\\n",
       "0                  من/دوست/دارم/بروم/خانه/درس/بخوانم   \n",
       "1        می‌توانی/من را/ببری/خانه‌مان/کمی/نان/بردارم   \n",
       "2  رفتم/درمانگاه/برای/بچه‌ام/دوا/بگیرم/یکهو/باران...   \n",
       "3               شاهد است/او/که/خدا/مثل/دیوانه‌ها است   \n",
       "4  یک/سری/آدم‌ها/هستند/که/هر/قدر/خوبی/کنی/اصلاً/ا...   \n",
       "\n",
       "                                       inFormalWords  \n",
       "0                     من/دوس/دارم/برم/خونه/درس/بخونم  \n",
       "1              میتونی/منو/ببری/خونمون/یکم/نون/وردارم  \n",
       "2    رفتم/درمونگاه/واسه/بچم/دوا/بگیرم/یهو/بارون/گرفت  \n",
       "3                     شاهده/اون/که/خدا/مث/دیوونه هاس  \n",
       "4  یه/سری/آدما/هستن/که/هر/قدر/خوبی/کنی/اصلن/انگار...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parsmap['formalForm'] = df_parsmap['formalForm'].progress_apply(normalize_text)\n",
    "df_parsmap['inFormalForm'] = df_parsmap['inFormalForm'].progress_apply(normalize_text)\n",
    "\n",
    "df_parsmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:56.496589Z",
     "iopub.status.busy": "2025-08-17T14:47:56.496350Z",
     "iopub.status.idle": "2025-08-17T14:47:56.523356Z",
     "shell.execute_reply": "2025-08-17T14:47:56.522742Z",
     "shell.execute_reply.started": "2025-08-17T14:47:56.496559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_parsmap = df_parsmap.dropna(subset=[\"inFormalForm\", \"formalForm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:56.524228Z",
     "iopub.status.busy": "2025-08-17T14:47:56.524060Z",
     "iopub.status.idle": "2025-08-17T14:47:56.528324Z",
     "shell.execute_reply": "2025-08-17T14:47:56.527513Z",
     "shell.execute_reply.started": "2025-08-17T14:47:56.524214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "base_model_id = \"universitytehran/PersianMind-v1.0\"\n",
    "compute_dtype = torch.bfloat16 if torch.cuda.get_device_capability(0)[0] >= 8 else torch.float16\n",
    "\n",
    "print(\"Compute dtype:\", compute_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:56.529491Z",
     "iopub.status.busy": "2025-08-17T14:47:56.528931Z",
     "iopub.status.idle": "2025-08-17T14:47:56.928350Z",
     "shell.execute_reply": "2025-08-17T14:47:56.927778Z",
     "shell.execute_reply.started": "2025-08-17T14:47:56.529468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def safe_str(x):\n",
    "    return \"\" if x is None or (isinstance(x, float) and np.isnan(x)) else str(x)\n",
    "\n",
    "df = df_parsmap.copy()\n",
    "df = df.dropna(subset=[\"inFormalForm\",\"formalForm\"])  # keep only rows with both sides\n",
    "\n",
    "def make_text(row):\n",
    "    informal = safe_str(row[\"inFormalForm\"])\n",
    "    formal   = safe_str(row[\"formalForm\"])\n",
    "    return f\"<s><|startoftext|>[Informal]{informal}[Formal]{formal}<|endoftext|>\"\n",
    "\n",
    "df[\"text\"] = df.apply(make_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:47:56.929253Z",
     "iopub.status.busy": "2025-08-17T14:47:56.929042Z",
     "iopub.status.idle": "2025-08-17T14:47:57.136352Z",
     "shell.execute_reply": "2025-08-17T14:47:57.135524Z",
     "shell.execute_reply.started": "2025-08-17T14:47:56.929236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45011, 5002)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90/10 split\n",
    "perm = np.random.permutation(len(df))\n",
    "cut = int(0.9*len(df))\n",
    "train_df = df.iloc[perm[:cut]].reset_index(drop=True)\n",
    "val_df   = df.iloc[perm[cut:]].reset_index(drop=True)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df[[\"text\"]]),\n",
    "    \"validation\": Dataset.from_pandas(val_df[[\"text\"]]),\n",
    "})\n",
    "len(ds[\"train\"]), len(ds[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T06:14:10.661609Z",
     "iopub.status.busy": "2025-08-17T06:14:10.661354Z",
     "iopub.status.idle": "2025-08-17T06:14:13.394644Z",
     "shell.execute_reply": "2025-08-17T06:14:13.393968Z",
     "shell.execute_reply.started": "2025-08-17T06:14:10.661592Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844844afa5774169ba5cb699b5f86432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631878e198054e66886801f62868e01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/688k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2305c0f41b504c68b503ad31ff8d7a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f5f436d335476292307b68a97faeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455f212bcbc341faa0c0e3682bc28f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/549 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added new tokens: 5\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True, trust_remote_code=True)\n",
    "\n",
    "specials = {\n",
    "    \"bos_token\": \"<s>\",\n",
    "    \"eos_token\": \"</s>\",\n",
    "    \"pad_token\": \"<pad>\",\n",
    "}\n",
    "# Make sure tokens exist\n",
    "for k,v in specials.items():\n",
    "    if getattr(tokenizer, k, None) != v:\n",
    "        tokenizer.add_special_tokens({k: v})\n",
    "\n",
    "added = tokenizer.add_tokens([\"<|startoftext|>\", \"<|endoftext|>\", \"[Informal]\", \"[Formal]\", \"<sep>\"], special_tokens=True)\n",
    "print(\"Added new tokens:\", added)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T06:14:13.395495Z",
     "iopub.status.busy": "2025-08-17T06:14:13.395301Z",
     "iopub.status.idle": "2025-08-17T06:16:57.239806Z",
     "shell.execute_reply": "2025-08-17T06:16:57.239232Z",
     "shell.execute_reply.started": "2025-08-17T06:14:13.395480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8179f4d53b4743acf0c485f47d9445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5410f4fc9045a6b8775364dbf913c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5979ae6cd6142ac9873ce6d3de37929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567216cab49b430890aa3c1486bb2f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b520e05315294c8796daf171ca3424df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f48c652b97411ab3467a5bb800c4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799380a6efd1416cb5c2dcd43b066c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/199 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.use_cache = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T06:16:57.240677Z",
     "iopub.status.busy": "2025-08-17T06:16:57.240502Z",
     "iopub.status.idle": "2025-08-17T06:16:57.962265Z",
     "shell.execute_reply": "2025-08-17T06:16:57.961418Z",
     "shell.execute_reply.started": "2025-08-17T06:16:57.240663Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 39,976,960 / Total: 3,618,344,960 (1.10%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16, lora_alpha=32, lora_dropout=0.1, bias=\"none\", task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable: {trainable:,} / Total: {total:,} ({100*trainable/total:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T06:16:57.963413Z",
     "iopub.status.busy": "2025-08-17T06:16:57.963126Z",
     "iopub.status.idle": "2025-08-17T06:17:01.957781Z",
     "shell.execute_reply": "2025-08-17T06:17:01.957013Z",
     "shell.execute_reply.started": "2025-08-17T06:16:57.963388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577313714a4a43af9eed8de50ef93491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a541f71bfa4bd1a581fd21c8903d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 64\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "tokenized = ds.map(tokenize_batch, batched=True, remove_columns=ds[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T06:17:01.959351Z",
     "iopub.status.busy": "2025-08-17T06:17:01.958575Z",
     "iopub.status.idle": "2025-08-17T06:17:01.962491Z",
     "shell.execute_reply": "2025-08-17T06:17:01.961948Z",
     "shell.execute_reply.started": "2025-08-17T06:17:01.959315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T06:17:01.963638Z",
     "iopub.status.busy": "2025-08-17T06:17:01.963280Z",
     "iopub.status.idle": "2025-08-17T06:17:02.011400Z",
     "shell.execute_reply": "2025-08-17T06:17:02.010701Z",
     "shell.execute_reply.started": "2025-08-17T06:17:01.963612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "effective_bs = 16 \n",
    "per_device_train_bs = 2\n",
    "per_device_eval_bs = 2\n",
    "grad_accum = max(1, effective_bs // per_device_train_bs)\n",
    "epochs = 1\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./persianmind-formalizer-lora\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=per_device_train_bs,\n",
    "    per_device_eval_batch_size=per_device_eval_bs,\n",
    "    gradient_accumulation_steps=grad_accum,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    weight_decay=0.001,\n",
    "    logging_steps=50,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,             \n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    bf16=(compute_dtype==torch.bfloat16),\n",
    "    fp16=(compute_dtype==torch.float16),\n",
    "\n",
    "    optim=\"paged_adamw_8bit\",          \n",
    "\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_persistent_workers=True,\n",
    "\n",
    "    group_by_length=True,              \n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T13:08:59.040Z",
     "iopub.execute_input": "2025-08-17T06:17:02.012422Z",
     "iopub.status.busy": "2025-08-17T06:17:02.012167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1898' max='2814' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1898/2814 4:45:09 < 2:17:45, 0.11 it/s, Epoch 0.67/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.120800</td>\n",
       "      <td>3.174871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.977600</td>\n",
       "      <td>3.109787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.922500</td>\n",
       "      <td>3.031685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For saving the model and pushing it to huggingface:\n",
    "\n",
    "- https://www.kaggle.com/code/sureshbeekhani/fine-tune-llama-2-7b-ipynb#Step-7:-Store-New-Llama2-Model-(Llama-2-7b-chat-finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T13:08:59.040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model = \"PersianMind-V1.0-formalizer-lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T13:08:59.041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:50:37.810545Z",
     "iopub.status.busy": "2025-08-17T14:50:37.810222Z",
     "iopub.status.idle": "2025-08-17T14:53:18.849228Z",
     "shell.execute_reply": "2025-08-17T14:53:18.848602Z",
     "shell.execute_reply.started": "2025-08-17T14:50:37.810524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ff53e0ca134a3f850f90cfdcf05bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c237dc1b808404f900d2e38b3315022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b867e040b847b1a5c529250cf8f14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562e6c458a944deea02d86a2506901d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56ff058ef9b4ecb8a42826119789587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a0519ca2f14e008169f2a6163e4b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd26bf6ddfc49d3b67f39e17e66cace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/199 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/persianmind-formalizer-lora/checkpoint-2814\")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, \"/kaggle/working/persianmind-formalizer-lora/checkpoint-2814\")\n",
    "\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:57:21.469218Z",
     "iopub.status.busy": "2025-08-17T14:57:21.468873Z",
     "iopub.status.idle": "2025-08-17T14:57:21.473199Z",
     "shell.execute_reply": "2025-08-17T14:57:21.472352Z",
     "shell.execute_reply.started": "2025-08-17T14:57:21.469194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:57:43.160660Z",
     "iopub.status.busy": "2025-08-17T14:57:43.160079Z",
     "iopub.status.idle": "2025-08-17T15:00:34.755641Z",
     "shell.execute_reply": "2025-08-17T15:00:34.755040Z",
     "shell.execute_reply.started": "2025-08-17T14:57:43.160637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "api_token = \"\"  \n",
    "login(token=api_token)\n",
    "\n",
    "model_name = \"AylinNaebzadeh/PersianMind-V1.0-formalizer-qlora\"\n",
    "\n",
    "model.push_to_hub(model_name, check_pr=True)\n",
    "\n",
    "tokenizer.push_to_hub(model_name, check_pr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T15:24:33.912545Z",
     "iopub.status.busy": "2025-08-17T15:24:33.912248Z",
     "iopub.status.idle": "2025-08-17T15:24:45.947647Z",
     "shell.execute_reply": "2025-08-17T15:24:45.946825Z",
     "shell.execute_reply.started": "2025-08-17T15:24:33.912525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained XLM-Roberta, this may take a while...\n",
      "Model fa_tokenizer exists in cache/dadmatools/fa_tokenizer.pt\n",
      "Loading tokenizer for persian\n",
      "Loading multi-word expander for persian\n",
      "==================================================\n",
      "Active language: persian\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import dadmatools.pipeline.language as language\n",
    "\n",
    "# here lemmatizer and pos tagger will be loaded\n",
    "# as tokenizer is the default tool, it will be loaded as well even without calling\n",
    "pips = 'tok'\n",
    "nlp = language.Pipeline(pips)\n",
    "# doc is now a proper spaCy Doc object\n",
    "doc = nlp('کشور بزرگ ایران توانسته در طی سال‌ها اقشار مختلفی از قومیت‌های گوناگون را به خوبی در خودش جا بده')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T15:26:08.911586Z",
     "iopub.status.busy": "2025-08-17T15:26:08.911249Z",
     "iopub.status.idle": "2025-08-17T15:26:08.917013Z",
     "shell.execute_reply": "2025-08-17T15:26:08.916428Z",
     "shell.execute_reply.started": "2025-08-17T15:26:08.911564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "کشور بزرگ ایران توانسته در طی سال‌ها اقشار مختلفی از قومیت‌های گوناگون را به خوبی در خودش جا بده"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T15:56:15.085119Z",
     "iopub.status.busy": "2025-08-17T15:56:15.084524Z",
     "iopub.status.idle": "2025-08-17T15:56:15.091107Z",
     "shell.execute_reply": "2025-08-17T15:56:15.090237Z",
     "shell.execute_reply.started": "2025-08-17T15:56:15.085092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, re, random\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def generator(informal, max_length=64, num_return_sequences=1):\n",
    "    # <s><|startoftext|>[Informal]{informal}[Formal]{formal}<|endoftext|>\n",
    "    model.eval()\n",
    "    prompt = f\"<s><|startoftext|>[Informal]{normalize_text(informal)}[Formal]\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    decoded_outputs = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        max_new_tokens=64,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=num_return_sequences\n",
    "    )\n",
    "\n",
    "    outputs = []\n",
    "    for output in decoded_outputs:\n",
    "        o = tokenizer.decode(output, skip_special_tokens=False)\n",
    "        o = o.replace(\"<s>\", \"\").replace(\"</s>\", \"\").replace(\"<|startoftext|>\", \"\").replace(\"<|endoftext|>\", \"\").replace(\"<pad>\", \"\")\n",
    "        pattern = r'\\[Informal\\].*?\\[Formal\\]'\n",
    "        o = re.sub(pattern, '', o)\n",
    "        outputs.append(o.strip())\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T15:55:30.176131Z",
     "iopub.status.busy": "2025-08-17T15:55:30.175587Z",
     "iopub.status.idle": "2025-08-17T15:55:30.181246Z",
     "shell.execute_reply": "2025-08-17T15:55:30.180619Z",
     "shell.execute_reply.started": "2025-08-17T15:55:30.176103Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['سلام', 'چطوری']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = doc.text\n",
    "words = word_tokenize(\"سلام چطوری\")\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T15:56:24.128912Z",
     "iopub.status.busy": "2025-08-17T15:56:24.128614Z",
     "iopub.status.idle": "2025-08-17T16:59:46.715362Z",
     "shell.execute_reply": "2025-08-17T16:59:46.714704Z",
     "shell.execute_reply.started": "2025-08-17T15:56:24.128890Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating outputs: 100%|██████████| 1000/1000 [1:03:21<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score on 1000 samples: 0.2516\n"
     ]
    }
   ],
   "source": [
    "sample_size = 1000\n",
    "sample_indices = random.sample(range(len(df_parsmap)), sample_size)\n",
    "\n",
    "reference_texts = [df_parsmap.iloc[i]['formalForm'] for i in sample_indices]\n",
    "# generated_texts = [generator(df_parsmap.iloc[i]['inFormalForm'], num_return_sequences=1)[0] for i in sample_indices]\n",
    "\n",
    "informal_texts = [df_parsmap.iloc[i]['inFormalForm'] for i in sample_indices]\n",
    "\n",
    "generated_texts = []\n",
    "for text in tqdm(informal_texts, desc=\"Generating outputs\"):\n",
    "    generated_texts.append(generator(text, num_return_sequences=1)[0])\n",
    "\n",
    "reference_tokens = [word_tokenize(text) for text in reference_texts]\n",
    "generated_tokens = [word_tokenize(text) for text in generated_texts]\n",
    "\n",
    "bleu_scores = []\n",
    "smoothing_func = SmoothingFunction().method1\n",
    "\n",
    "for ref_tokens, gen_tokens in zip(reference_tokens, generated_tokens):\n",
    "    bleu = sentence_bleu([ref_tokens], gen_tokens, smoothing_function=smoothing_func)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "print(f\"Average BLEU score on {sample_size} samples: {avg_bleu_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7556052,
     "sourceId": 12010481,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
